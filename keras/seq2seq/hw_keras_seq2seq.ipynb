{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "venv-lab",
      "language": "python",
      "name": "venv-lab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "hw-keras-seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QyFxkPUtsWkT",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.utils\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense, TimeDistributed, Masking, Bidirectional, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3i3vRS5VEc-",
        "colab_type": "code",
        "outputId": "c26d63c7-c837-4ba4-91cd-fb401084057a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFu3a8GVEdQ",
        "colab_type": "text"
      },
      "source": [
        "# General"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGfEf4PpVEdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet = list(\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.,;:!?-+*()[]&/ \\\"#\") # %:;&#\n",
        "alphabet.insert(0, chr(0)) # '\\x00' character, i.e., ord(0) to label concatenate\n",
        "alphabet.insert(1, '\\t') # start of sequence\n",
        "alphabet.insert(2, '\\n') # end of sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG2bUJsMVEde",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWQAB0qZVEdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timesteps = None\n",
        "input_features = 3\n",
        "encoder_space = 512\n",
        "decoder_space = encoder_space * 2\n",
        "decoder_timesteps = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zv7kBOVVEdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder\n",
        "encoder_input = Input(shape=(timesteps, input_features), name='encoder_input')\n",
        "masking_layer =  Masking(mask_value=0., input_shape=(timesteps, input_features), name='masking_encoder')(encoder_input)\n",
        "encoder_output, forward_h, forward_c, backward_h, backward_c= Bidirectional(LSTM(encoder_space, return_state=True), name=\"encoder\")(masking_layer)\n",
        "\n",
        "# merge states\n",
        "state_h = Concatenate(name=\"merge_h\")([forward_h, backward_h])\n",
        "state_c = Concatenate(name=\"merge_c\")([forward_c, backward_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "#Decoder\n",
        "decoder_input = Input(shape=(timesteps, len(alphabet)), name='decoder_input')\n",
        "decoder_masking = Masking(mask_value=0., input_shape=(timesteps, len(alphabet)), name=\"masking_decoder\")(decoder_input)\n",
        "decoder_outputs, _, _ = LSTM(decoder_space, return_sequences=True, return_state=True, name=\"decoder\")(decoder_masking, initial_state=encoder_states)\n",
        "decoder_dense = TimeDistributed(Dense(len(alphabet), activation='softmax'), name=\"dense_decoder\")(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrIyCtaCVEdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_input, decoder_input], decoder_dense)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDyZlZrwVEd4",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck1mww7KSU-V",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecLj-RvYj-Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgVZyfIsVe6T",
        "colab_type": "code",
        "outputId": "c47ecbb1-7895-4ff0-f774-081e0bd9da87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHZL8zT6Vf2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset = np.load('/content/drive/My Drive/deepwriting/deepwriting_training.npz', allow_pickle=True)\n",
        "validation_dataset = np.load('/content/drive/My Drive/deepwriting/deepwriting_validation.npz', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLiRxnqfSXgw",
        "colab_type": "text"
      },
      "source": [
        "## Generate Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ZeTbbeVEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36P5CFSGVEeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_to_length(sequences, max_len, two_dimensional=True):\n",
        "    padded_sequence = []\n",
        "    for seq in sequences:\n",
        "        pad_len = max_len - len(seq)\n",
        "        if two_dimensional:\n",
        "            padded_seq = np.pad(seq, [(0, pad_len), (0, 0)], mode='constant', constant_values=0)\n",
        "        else:\n",
        "            padded_seq = np.pad(seq, (0, pad_len), mode='constant', constant_values=0)\n",
        "            padded_seq = np.expand_dims(padded_seq, axis=1)\n",
        "        padded_sequence.append(padded_seq)\n",
        "    # check whether all lists have actually the same length\n",
        "    assert len(list(filter(lambda x: x != max_len, [len(seq) for seq in padded_sequence]))) == 0\n",
        "    return np.array(padded_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqgUkQM3RJ76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_encoder_data(dataset):\n",
        "  max_len_encoder = len(max(dataset, key=len))\n",
        "  encoder_input_data = pad_to_length(dataset, max_len_encoder)\n",
        "  return encoder_input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EqUZMr-OCDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_decoder_data(dataset, alphabet):\n",
        "  # Encoder for char labels\n",
        "  label_encoder = LabelEncoder()\n",
        "  label_encoder = label_encoder.fit(alphabet)\n",
        "\n",
        "  # Prepare texts\n",
        "  # \\t as starting point\n",
        "  # \\n as ending point\n",
        "  texts = ['\\t' + text + '\\n' for text in dataset]\n",
        "\n",
        "  # skip the '\\n' for input\n",
        "  # skip the '\\t' for output\n",
        "  decoder_input_texts  = [text[:-1] for text in texts]\n",
        "  decoder_output_texts = [text[1:]  for text in texts]\n",
        "\n",
        "  # Encode the texts\n",
        "  decoder_input_text_encoded = [\n",
        "                               label_encoder.transform([char for char in text])\n",
        "                               for text in decoder_input_texts\n",
        "                              ]\n",
        "\n",
        "  decoder_output_text_encoded = [\n",
        "                               label_encoder.transform([char for char in text])\n",
        "                               for text in decoder_output_texts\n",
        "                              ] \n",
        "\n",
        "  # Find max length for padding\n",
        "  max_len_decoder = len(max(decoder_input_texts, key=len))\n",
        "\n",
        "  # Pad texts\n",
        "  decoder_input_text_padded = pad_to_length(decoder_input_text_encoded, max_len_decoder, False)\n",
        "  decoder_output_text_padded = pad_to_length(decoder_output_text_encoded, max_len_decoder, False)\n",
        "\n",
        "  # transform to categorical\n",
        "  decoder_input_data = to_categorical(decoder_input_text_padded, num_classes=len(alphabet))\n",
        "  decoder_output_data = decoder_output_text_padded\n",
        "\n",
        "  return decoder_input_data, decoder_output_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDwNNkpNLCmd",
        "colab_type": "text"
      },
      "source": [
        "# Training texts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61TwGQCTR9oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_encoder_input_data = create_encoder_data(training_dataset['strokes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8QPLHcRgg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_decoder_input_data, training_decoder_output_data = create_decoder_data(training_dataset['texts'], alphabet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr7WRoWmNlA5",
        "colab_type": "text"
      },
      "source": [
        "## Validation Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyZ-_Z0DSG1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_encoder_input_data = create_encoder_data(validation_dataset['strokes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_xDU_nENyVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_decoder_input_data, validation_decoder_output_data = create_decoder_data(validation_dataset['texts'], alphabet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmA4ylNmVEfV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J1hHibGUleQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyD9b4ZwUntK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monitor = 'val_accuracy'\n",
        "mode='max'\n",
        "\n",
        "modelCheckpoint = ModelCheckpoint('./best_model_seq2seq_512.hdf5', monitor=monitor, save_best_only='True', mode=mode)\n",
        "earlyStopping = EarlyStopping(monitor=monitor, patience=10, mode=mode)\n",
        "reduceLROnPlateau = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, mode=mode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgn37kBdVEfX",
        "colab_type": "code",
        "outputId": "de0c2f03-c433-4488-8b1b-3788010d5cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(\n",
        "    [training_encoder_input_data, training_decoder_input_data], \n",
        "    training_decoder_output_data,\n",
        "    batch_size=256,\n",
        "    epochs=100 ,\n",
        "    callbacks=[modelCheckpoint, earlyStopping, reduceLROnPlateau],\n",
        "    validation_data=(\n",
        "        [\n",
        "         validation_encoder_input_data,\n",
        "         validation_decoder_input_data\n",
        "        ]\n",
        "        , validation_decoder_output_data\n",
        "    )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 34577 samples, validate on 705 samples\n",
            "Epoch 1/100\n",
            "34577/34577 [==============================] - 72s 2ms/sample - loss: 1.9929 - accuracy: 0.5517 - val_loss: 1.6666 - val_accuracy: 0.5570\n",
            "Epoch 2/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 1.3872 - accuracy: 0.6315 - val_loss: 1.3339 - val_accuracy: 0.6338\n",
            "Epoch 3/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 1.1367 - accuracy: 0.6753 - val_loss: 1.1634 - val_accuracy: 0.6637\n",
            "Epoch 4/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 1.0091 - accuracy: 0.7055 - val_loss: 1.0669 - val_accuracy: 0.6875\n",
            "Epoch 5/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.9085 - accuracy: 0.7317 - val_loss: 0.9759 - val_accuracy: 0.7104\n",
            "Epoch 6/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.8131 - accuracy: 0.7590 - val_loss: 0.9029 - val_accuracy: 0.7291\n",
            "Epoch 7/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.7129 - accuracy: 0.7889 - val_loss: 0.8159 - val_accuracy: 0.7557\n",
            "Epoch 8/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.6060 - accuracy: 0.8229 - val_loss: 0.7414 - val_accuracy: 0.7783\n",
            "Epoch 9/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.5034 - accuracy: 0.8559 - val_loss: 0.6708 - val_accuracy: 0.8005\n",
            "Epoch 10/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.4143 - accuracy: 0.8840 - val_loss: 0.5897 - val_accuracy: 0.8254\n",
            "Epoch 11/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.3432 - accuracy: 0.9055 - val_loss: 0.5180 - val_accuracy: 0.8499\n",
            "Epoch 12/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.2891 - accuracy: 0.9212 - val_loss: 0.4560 - val_accuracy: 0.8695\n",
            "Epoch 13/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.2496 - accuracy: 0.9323 - val_loss: 0.4103 - val_accuracy: 0.8836\n",
            "Epoch 14/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.3905 - val_accuracy: 0.8898\n",
            "Epoch 15/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1988 - accuracy: 0.9456 - val_loss: 0.3663 - val_accuracy: 0.8958\n",
            "Epoch 16/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1828 - accuracy: 0.9498 - val_loss: 0.3381 - val_accuracy: 0.9043\n",
            "Epoch 17/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1702 - accuracy: 0.9528 - val_loss: 0.3271 - val_accuracy: 0.9075\n",
            "Epoch 18/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1595 - accuracy: 0.9555 - val_loss: 0.3151 - val_accuracy: 0.9106\n",
            "Epoch 19/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1509 - accuracy: 0.9575 - val_loss: 0.3151 - val_accuracy: 0.9120\n",
            "Epoch 20/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1428 - accuracy: 0.9596 - val_loss: 0.3048 - val_accuracy: 0.9149\n",
            "Epoch 21/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1358 - accuracy: 0.9614 - val_loss: 0.2910 - val_accuracy: 0.9197\n",
            "Epoch 22/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1293 - accuracy: 0.9631 - val_loss: 0.2903 - val_accuracy: 0.9197\n",
            "Epoch 23/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1229 - accuracy: 0.9648 - val_loss: 0.2863 - val_accuracy: 0.9216\n",
            "Epoch 24/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1168 - accuracy: 0.9665 - val_loss: 0.2791 - val_accuracy: 0.9251\n",
            "Epoch 25/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1111 - accuracy: 0.9682 - val_loss: 0.2941 - val_accuracy: 0.9188\n",
            "Epoch 26/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1053 - accuracy: 0.9698 - val_loss: 0.2941 - val_accuracy: 0.9218\n",
            "Epoch 27/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.1002 - accuracy: 0.9713 - val_loss: 0.2833 - val_accuracy: 0.9252\n",
            "Epoch 28/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0795 - accuracy: 0.9786 - val_loss: 0.2234 - val_accuracy: 0.9420\n",
            "Epoch 29/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0659 - accuracy: 0.9830 - val_loss: 0.2260 - val_accuracy: 0.9416\n",
            "Epoch 30/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0615 - accuracy: 0.9844 - val_loss: 0.2309 - val_accuracy: 0.9412\n",
            "Epoch 31/100\n",
            "34577/34577 [==============================] - 60s 2ms/sample - loss: 0.0584 - accuracy: 0.9854 - val_loss: 0.2347 - val_accuracy: 0.9406\n",
            "Epoch 32/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.2353 - val_accuracy: 0.9404\n",
            "Epoch 33/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0537 - accuracy: 0.9872 - val_loss: 0.2361 - val_accuracy: 0.9402\n",
            "Epoch 34/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0533 - accuracy: 0.9873 - val_loss: 0.2368 - val_accuracy: 0.9403\n",
            "Epoch 35/100\n",
            "34577/34577 [==============================] - 60s 2ms/sample - loss: 0.0528 - accuracy: 0.9875 - val_loss: 0.2369 - val_accuracy: 0.9402\n",
            "Epoch 36/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0527 - accuracy: 0.9875 - val_loss: 0.2370 - val_accuracy: 0.9402\n",
            "Epoch 37/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0527 - accuracy: 0.9875 - val_loss: 0.2371 - val_accuracy: 0.9402\n",
            "Epoch 38/100\n",
            "34577/34577 [==============================] - 59s 2ms/sample - loss: 0.0526 - accuracy: 0.9875 - val_loss: 0.2371 - val_accuracy: 0.9402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ff7f629e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WiYDsFiVEfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB5-CPbPVEfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}