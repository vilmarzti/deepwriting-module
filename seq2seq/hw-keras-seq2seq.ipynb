{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QyFxkPUtsWkT",
    "outputId": "72e911d0-aed9-4604-b516-d21056017a8f"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.utils\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, TimeDistributed, Masking, Bidirectional, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list(\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.,;:!?-+*()[]&/ \\\"#\") # %:;&#\n",
    "alphabet.insert(0, chr(0)) # '\\x00' character, i.e., ord(0) to label concatenate\n",
    "alphabet.insert(1, '\\t') # start of sequence\n",
    "alphabet.insert(2, '\\n') # end of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = None\n",
    "input_features = 3\n",
    "encoder_space = 512\n",
    "decoder_space = encoder_space * 2\n",
    "decoder_timesteps = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_input = Input(shape=(timesteps, input_features), name='encoder_input')\n",
    "masking_layer =  Masking(mask_value=0., input_shape=(timesteps, input_features))(encoder_input)\n",
    "encoder_output, forward_h, forward_c, backward_h, backward_c= Bidirectional(LSTM(encoder_space, return_state=True))(masking_layer)\n",
    "\n",
    "# merge states\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Decoder\n",
    "decoder_input = Input(shape=(timesteps, len(alphabet)), name='decoder_input')\n",
    "decoder_outputs, _, _ = LSTM(decoder_space, return_sequences=True, return_state=True)(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(alphabet), activation='softmax')(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_length(sequences, max_len, two_dimensional=True):\n",
    "    padded_sequence = []\n",
    "    for seq in sequences:\n",
    "        pad_len = max_len - len(seq)\n",
    "        if two_dimensional:\n",
    "            padded_seq = np.pad(seq, [(0, pad_len), (0, 0)], mode='constant', constant_values=0)\n",
    "        else:\n",
    "            padded_seq = np.pad(seq, (0, pad_len), mode='constant', constant_values=0)\n",
    "            padded_seq = np.expand_dims(padded_seq, axis=1)\n",
    "        padded_sequence.append(padded_seq)\n",
    "    # check whether all lists have actually the same length\n",
    "    assert len(list(filter(lambda x: x != max_len, [len(seq) for seq in padded_sequence]))) == 0\n",
    "    return np.array(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = np.load('/home/martin/Downloads/deepwriting_dataset/deepwriting_training.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject_labels',\n",
       " 'eoc_labels',\n",
       " 'alphabet',\n",
       " 'strokes',\n",
       " 'eow_labels',\n",
       " 'char_labels',\n",
       " 'word_labels',\n",
       " 'max',\n",
       " 'min',\n",
       " 'soc_labels',\n",
       " 'mean',\n",
       " 'texts',\n",
       " 'std',\n",
       " 'preprocessing',\n",
       " 'sow_labels']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(training_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_training_encoder = len(max(training_dataset['strokes'], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = pad_to_length(training_dataset['strokes'], max_len_training_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34577, 489, 3)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_texts = [\"\\t\" + text for text in training_dataset['texts']]\n",
    "decoder_input_data = [label_encoder.transform([char for char in text]) for text in decoder_input_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_training_decoder = len(max(decoder_input_data, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34577, 65, 84)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data = pad_to_length(decoder_input_data, max_len_training_decoder, False)\n",
    "decoder_input_data = to_categorical(decoder_input_data, num_classes=len(alphabet))\n",
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_texts = [text + \"\\n\" for text in training_dataset['texts']]\n",
    "decoder_output_data = [label_encoder.transform([char for char in text]) for text in decoder_input_texts]\n",
    "decoder_output_data = pad_to_length(decoder_output_data, max_len_training_decoder, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34577 samples\n",
      "   64/34577 [..............................] - ETA: 3:56:03 - loss: 7.7500 - accuracy: 0.2474    "
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-lab",
   "language": "python",
   "name": "venv-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
